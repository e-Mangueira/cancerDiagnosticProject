{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Ignore warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import dataset    \n",
    "Link: https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/mangueira/Library/Mobile Documents/com~apple~CloudDocs/devNilton/projetoFinal_IA4/projectNilton/datasetDiagnostic.csv'\n",
    "dataExams_v0 = pd.read_csv (path, sep=',', encoding='utf-8')\n",
    "dataExams_v0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataExams_v0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show column \"exame_33\" 419 null instances (more than 90%):\n",
    "dataExams_v0.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns:\n",
    "## \"Id\" (non-numeric data); \"Diagnostic\" (dataset outputs examples) and \"Exam_33\" (more than 90% NaN)\n",
    "dataExams_v1 = dataExams_v0.drop(columns=['Id', 'Diagnostic', 'Exam_33'])\n",
    "\n",
    "dataExams_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected output (label):\n",
    "diagnostic = dataExams_v0.Diagnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Criando modelo de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Using train_test_split:    \n",
    "    Split arrays or matrices into random train and test subsets.        \n",
    "    Link: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import random\n",
    "\n",
    "SEED = 123143\n",
    "random.seed(SEED)\n",
    "\n",
    "training_x, test_x, training_y, test_y = train_test_split(dataExams_v1, \n",
    "                                                          diagnostic,\n",
    "                                                          test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Training (70%) and Test (30%) data:\n",
    "\n",
    "print(\"Training data (70%):\", training_x.shape, training_y.shape, \"\\n\"\n",
    "          \"Test data (30%):\", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset (examples):\n",
    "training_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Know outputs (labels):\n",
    "training_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Using RandomForestClassifier:    \n",
    "    A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples\n",
    "     the dataset and uses averaging to improve the predictive accuracy and control over-fitting.    \n",
    "    Link: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy import random\n",
    "\n",
    "# Modelo 1:\n",
    "classifier = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "classifier.fit(training_x, training_y)\n",
    "\n",
    "# Reference baseline_1 before reducing data dimensionality using RandomForestClassifier:\n",
    "print(\"RandomForestClassifier (reference baseline_1) = %.2f%%\" %(classifier.score(test_x,test_y)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Dummy simple classifyion (DummyClassifier):    \n",
    "    This classifier serves as a simple baseline to compare against other more complex classifiers.    \n",
    "    Link: https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "SEED = 123143\n",
    "random.seed(SEED)\n",
    "\n",
    "classifier_simple1 = DummyClassifier(strategy= \"most_frequent\")\n",
    "classifier_simple1.fit(training_x, training_y)\n",
    "\n",
    "# Simple classification result using Dummy (baseline_2):\n",
    "print(\"DummyClassifier (reference baseline_2) = %.2f%%\" %(classifier_simple1.score(test_x, test_y)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Methods (1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier (reference baseline_1) before reducing data dimensionality using :\n",
    "print(\"1 - RandomForestClassifier (reference baseline_1) = %.2f%%\"\"\\n\" %(classifier.score(test_x,test_y)*100))\n",
    "# Simple classification result using Dummy (baseline_2):\n",
    "print(\"2 - DummyClassifier (referencebaseline_2) = %.2f%%\" %(classifier_simple1.score(test_x, test_y)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Analyze the data for model fits      \n",
    "Best for graphics visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  5.1 Concatenate dataset     \n",
    "(Diagnostic + dataExams_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset (Diagnostic + dataExams_v1)\n",
    "data_plot = pd.concat([diagnostic, dataExams_v1],axis = 1)\n",
    "data_plot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Using pandas.melt   \n",
    "Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.   \n",
    "Link: https://pandas.pydata.org/docs/reference/api/pandas.melt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_plot = pd.melt(data_plot, \n",
    "                     id_vars=\"Diagnostic\",\n",
    "                     var_name=\"Exams\",\n",
    "                     value_name='values')\n",
    "data_plot.head(569)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 seaborn.violinplot   \n",
    "Draw a combination of boxplot and kernel density estimate.    \n",
    "https://seaborn.pydata.org/generated/seaborn.violinplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data_plot = pd.concat([diagnostic, dataExams_v1.iloc[:,0:10]],axis = 1)\n",
    "\n",
    "data_plot = pd.melt(data_plot,\n",
    "                    id_vars=\"Diagnostic\",\n",
    "                    var_name=\"Exams\",\n",
    "                    value_name='values')\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.violinplot(x = \"Exams\", y = \"values\", hue = \"Diagnostic\",\n",
    "               data = data_plot)\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Using function StandardScaler (standardize)   \n",
    "Standardize features by removing the mean and scaling to unit variance.   \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard = StandardScaler()\n",
    "\n",
    "standard.fit(dataExams_v1)\n",
    "\n",
    "dataExams_v3 = standard.transform(dataExams_v1)\n",
    "\n",
    "dataExams_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard = StandardScaler()\n",
    "\n",
    "standard.fit(dataExams_v1)\n",
    "\n",
    "dataExams_v3 = standard.transform(dataExams_v1)\n",
    "\n",
    "dataExams_v3 = pd.DataFrame(data = dataExams_v3,\n",
    "                              columns = dataExams_v1.keys())\n",
    "\n",
    "data_plot = pd.concat([diagnostic, dataExams_v3.iloc[:,0:10]],axis = 1)\n",
    "\n",
    "data_plot = pd.melt(data_plot,\n",
    "                    id_vars=\"Diagnostic\",\n",
    "                    var_name=\"Exams\",\n",
    "                    value_name='values')\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "sns.violinplot(x = \"Exams\", y = \"values\", hue = \"Diagnostic\",\n",
    "               data = data_plot, split= True)\n",
    "\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violinPlot(values, inicio, fim):\n",
    "    \n",
    "    data_plot = pd.concat([diagnostic, values.iloc[:,inicio:fim]],axis = 1)\n",
    "    \n",
    "    data_plot = pd.melt(data_plot,\n",
    "                        id_vars=\"Diagnostic\",\n",
    "                        var_name=\"Exams\",\n",
    "                        value_name='values')\n",
    "    \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    sns.violinplot(x = \"Exams\", y = \"values\", hue = \"Diagnostic\",\n",
    "                   data = data_plot, split= True)\n",
    "    \n",
    "    plt.xticks(rotation = 90)\n",
    "\n",
    "violinPlot(dataExams_v3, 0, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  3.4 Remove values (Exam_3 e Exam_29)   \n",
    "## Constant values in this data (line)\n",
    "\n",
    "dataExams_v4 = dataExams_v3.drop(columns=[\"Exam_29\", \"Exam_4\"])\n",
    "\n",
    "dataExams_v4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViolinPlot adjusted\n",
    "\n",
    "def violinPlot(values, inicio, fim):\n",
    "    \n",
    "    data_plot = pd.concat([diagnostic, values.iloc[:,inicio:fim]],axis = 1)\n",
    "    \n",
    "    data_plot = pd.melt(data_plot,\n",
    "                        id_vars=\"Diagnostic\",\n",
    "                        var_name=\"Exams\",\n",
    "                        value_name='values')\n",
    "    \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    sns.violinplot(x = \"Exams\", y = \"values\", hue = \"Diagnostic\",\n",
    "                   data = data_plot, split= True)\n",
    "    \n",
    "    plt.xticks(rotation = 90)\n",
    "\n",
    "violinPlot(dataExams_v4, 0, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Repeat RandomForestClassifier (after data adjustments) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "\n",
    "def classify (values):\n",
    "    SEED = 1234\n",
    "    random.seed(SEED)\n",
    "   \n",
    "    training_x, test_x, training_y, test_y = train_test_split(values, \n",
    "                                                        diagnostic,\n",
    "                                                        test_size = 0.3)\n",
    "\n",
    "    classifier = RandomForestClassifier(n_estimators = 100)\n",
    "    \n",
    "    classifier.fit(training_x, training_y)\n",
    "    \n",
    "    print(\"3 - RandomForestClassifier (reference baseline_3) = %.2f%%\" %(classifier.score(test_x,test_y)*100))\n",
    "\n",
    "classify(dataExams_v4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Methods (2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier (reference baseline_1) before reducing data dimensionality using :\n",
    "print(\"1 - RandomForestClassifier (reference baseline_1) = %.2f%%\" \"\\n\" %(classifier.score(test_x,test_y)*100))\n",
    "\n",
    "# Simple classification result using Dummy (baseline_2):\n",
    "print(\"2 - DummyClassifier (reference baseline_2) = %.2f%%\" \"\\n\" %(classifier_simple1.score(test_x, test_y)*100))\n",
    "\n",
    "# RandomForestClassifier (reference baseline_3) after adjusted data:\n",
    "classify(dataExams_v4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Matrix correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Heat map    \n",
    "Plot rectangular data as a color-encoded matrix.   \n",
    "Link: https://seaborn.pydata.org/generated/seaborn.heatmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixCorrelation = dataExams_v4.corr()\n",
    "plt.figure(figsize = (17, 15))\n",
    "sns.heatmap(matrixCorrelation, annot = True, fmt = \".1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixCorrelation_v1 = matrixCorrelation[matrixCorrelation>0.99]\n",
    "matrixCorrelation_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixCorrelation_v2 = matrixCorrelation_v1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixCorrelation_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_correlacionadas = matrixCorrelation_v2[matrixCorrelation_v2>1]\n",
    "variaveis_correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExams_v5 = dataExams_v4.drop(columns=variaveis_correlacionadas.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExams_v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(dataExams_v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExams_v6 = dataExams_v4.drop(columns=[\"Exam_3\", \"Exam_24\"])\n",
    "classify(dataExams_v6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "selecionar_kmelhores = SelectKBest(chi2, k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x, test_x, training_y, test_y = train_test_split(dataExams_v6, \n",
    "                                                        diagnostic,\n",
    "                                                        test_size = 0.3)\n",
    "\n",
    "selecionar_kmelhores.fit(training_x,training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExams_v7 = dataExams_v2.drop(columns=([\"Exam_4\", \"Exam_29\", \"Exam_3\", \"Exam_24\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED= 1234\n",
    "random.seed(SEED)\n",
    "\n",
    "training_x, test_x, training_y, test_y = train_test_split(dataExams_v7, \n",
    "                                                        diagnostic,\n",
    "                                                        test_size = 0.3)\n",
    "\n",
    "\n",
    "selecionar_kmelhores.fit(training_x,training_y)\n",
    "training_kbest = selecionar_kmelhores.transform(training_x)\n",
    "test_kbest = selecionar_kmelhores.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kbest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=1234)\n",
    "classifier.fit(training_kbest, training_y)\n",
    "print(\"Resultado da classificação %.2f%%\" %(classifier.score(test_kbest,test_y)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5/33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matriz_confusao = confusion_matrix(test_y,classifier.predict(test_kbest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "sns.set(font_scale= 2)\n",
    "sns.heatmap(matriz_confusao, annot = True, fmt = \"d\").set(xlabel = \"Predição\", ylabel= \"Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "SEED= 1234\n",
    "random.seed(SEED)\n",
    "\n",
    "training_x, test_x, training_y, test_y = train_test_split(dataExams_v7, \n",
    "                                                        diagnostic,\n",
    "                                                        test_size = 0.3)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=1234)\n",
    "classifier.fit(training_x, training_y)\n",
    "selecionador_rfe = RFE(estimator = classifier, n_features_to_select = 5, step = 1)\n",
    "selecionador_rfe.fit(training_x, training_y)\n",
    "training_rfe = selecionador_rfe.transform(training_x)\n",
    "test_rfe = selecionador_rfe.transform(test_x)\n",
    "classifier.fit(training_rfe, training_y)\n",
    "\n",
    "matriz_confusao = confusion_matrix(test_y,classifier.predict(test_rfe))\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.set(font_scale= 2)\n",
    "sns.heatmap(matriz_confusao, annot = True, fmt = \"d\").set(xlabel = \"Predição\", ylabel= \"Real\")\n",
    "\n",
    "print(\"Resultado da classificação %.2f%%\" %(classifier.score(test_rfe,test_y)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
